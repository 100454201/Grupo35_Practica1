{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Tratamiento de datos\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Gráficos\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "\"\"\"\n",
    "# Preprocesado y modelado\n",
    "# ==============================================================================\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "\n",
    "# Configuración matplotlib\n",
    "# ==============================================================================\n",
    "plt.rcParams['image.cmap'] = \"bwr\"\n",
    "plt.rcParams['savefig.bbox'] = \"tight\"\n",
    "style.use('ggplot') or plt.style.use('ggplot')\n",
    "\n",
    "# Configuración warnings\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('attrition_availabledata_35.csv.gz', compression=\"gzip\")\n",
    "\n",
    "#Informción general\n",
    "data.info()\n",
    "#Variable objetivo\n",
    "data.Attrition.value_counts().sort_index() #Número de muestras por clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datos de las variables numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos borrando las columnas que aportan datos irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable a estudiar BussineTravel\n",
    "print(data[\"BusinessTravel\"].value_counts()) #Parece que tiene valores distribuidos, por lo que la vamos a dejar\n",
    "\n",
    "#Variable a estudiar EmployeeCount\n",
    "print(data[\"EmployeeCount\"].value_counts())  #Solo tiene un único valor, por lo que es una variable descartable\n",
    "\n",
    "#La variable EmployeeID es irrelevante en el modelo, por lo que la descartamos igual\n",
    "\n",
    "#Variable a estudiar Over18\n",
    "print(data[\"Over18\"].value_counts()) #Único valor --> descartable\n",
    "\n",
    "#Variable a estudiar StandardHours\n",
    "print(data[\"StandardHours\"].value_counts()) #Único valor --> descartable\n",
    "\n",
    "#Variable a estudiar TrainigTimesLastYears\n",
    "print(data[\"TrainingTimesLastYear\"].value_counts()) #Valores Distribuidos\n",
    "\n",
    "#Vamos a eliminar EmployeeCount, Over18, StandardHours y EmployeeID  por ser irrelevante o tener un único valor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de columnas a eliminar\n",
    "cols_to_drop = [\"EmployeeID\", \"EmployeeCount\", \"Over18\", \"StandardHours\"]\n",
    "\n",
    "# Eliminamos las columnas del dataset\n",
    "data = data.drop(columns=cols_to_drop)\n",
    "\n",
    "# Verificamos\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos ahora 26 variables a estudiar. Vamos hacer una matriz de correlación para ver si podemos descartar algunas más. Primero tendremos que filtrar los valores numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Attrition\"] = data[\"Attrition\"].map({\"Yes\": 1, \"No\": 0})\n",
    "numeric_data = data.select_dtypes(include=[\"number\"])\n",
    "\n",
    "corr_matrix = numeric_data.corr()\n",
    "f,ax = plt.subplots(figsize=(18, 18))\n",
    "sns.heatmap (corr_matrix, linewidths = 0.5, annot = True, fmt= '.1f',ax=ax)\n",
    "plt.show ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Existen dos parejas de variables con una correlación de 0.8 (PercentSalaryHike/PerformanceRating y YearsInCompany/YearsWithCurrentMananger)\n",
    "Voy a descartar una variable de cada pareja, en este caso PerformanceRating y YearsAtCompany\n",
    "\"\"\"\n",
    "\n",
    "# Lista de columnas a eliminar\n",
    "cols_to_drop = [\"PerformanceRating\", \"YearsAtCompany\"]\n",
    "\n",
    "# Eliminamos las columnas del dataset\n",
    "data = data.drop(columns=cols_to_drop)\n",
    "\n",
    "# Verificamos\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora queremos descartar aquuelas variables que estan poco correlacionadas con la variable objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corr_with_target = numeric_data.corr()[\"Attrition\"].sort_values(ascending=False)\n",
    "#Mostramos las variables menos correlacionadas\n",
    "print(corr_with_target.head(24))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a quitar aquellas que tengan una correlación menor a |0.03| "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el umbral de correlación\n",
    "threshold = 0.03  \n",
    "\n",
    "# Recalcular la matriz de correlación con las columnas actuales del dataset\n",
    "corr_matrix = data.select_dtypes(include=[\"number\"]).corr()\n",
    "\n",
    "# Obtener la correlación con Attrition\n",
    "corr_with_target = corr_matrix[\"Attrition\"].abs()\n",
    "\n",
    "# Identificar columnas con correlación menor a 0.03 (demasiado bajas)\n",
    "columns_to_drop = corr_with_target[corr_with_target < threshold].index\n",
    "\n",
    "# Filtrar solo las columnas que realmente existen en el DataFrame antes de eliminarlas\n",
    "columns_to_drop = [col for col in columns_to_drop if col in data.columns]\n",
    "\n",
    "# Eliminar las columnas con baja correlación\n",
    "data_filtered = data.drop(columns=columns_to_drop)\n",
    "\n",
    "# Mostrar las columnas restantes\n",
    "print(\"Columnas que se mantienen:\", data_filtered.columns.tolist())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
